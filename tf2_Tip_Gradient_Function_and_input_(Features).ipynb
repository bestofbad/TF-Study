{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b7018f5",
   "metadata": {},
   "source": [
    "# Gradient 함수에서 input (Features) 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "934835f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "tf.random.set_seed(777)  # for reproducibility\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6878e88c",
   "metadata": {},
   "source": [
    "## Data (features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32b9bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "\n",
    "y_train = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "features = tf.cast(x_train, tf.float32)\n",
    "labels = tf.cast(y_train, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584638bd",
   "metadata": {},
   "source": [
    "## 가중치 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc116c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.normal((3, 3)))\n",
    "b = tf.Variable(tf.random.normal((3,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2046931a",
   "metadata": {},
   "source": [
    "## Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d661d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(features):\n",
    "    hypothesis = tf.nn.softmax(tf.matmul(features, W) +b)\n",
    "    return hypothesis\n",
    "\n",
    "hypothesis = model(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b667f7e",
   "metadata": {},
   "source": [
    "## Cost 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ba2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(hypothesis,labels):\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(labels * tf.math.log(hypothesis), axis = 1))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff05d82a",
   "metadata": {},
   "source": [
    "## Gradient 함수 Input\n",
    "\n",
    "- input 변수는 features (x data)가 직접 되어야 함.\n",
    "- for 문에서 features와 hypothesis 관계가 선언되더라도, hypothesis로 계산된 후 input이 되면 gard. 계산 안됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c126d",
   "metadata": {},
   "source": [
    "### 1. grad(features, labels)로 선언한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c238befc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       " array([[-0.24937233, -0.3747183 ,  0.6240906 ],\n",
       "        [-1.6237042 , -1.7494293 ,  3.3731337 ],\n",
       "        [-1.6243054 , -1.8747082 ,  3.4990134 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([-0.24937233, -0.3747183 ,  0.6240906 ], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grad(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(model(features),labels)\n",
    "    return tape.gradient(loss_value, [W,b])\n",
    "\n",
    "grad(features, labels)                 # 정상 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4388d0e",
   "metadata": {},
   "source": [
    "### 2. grad(hypothesis, labels)로 선언한 경우\n",
    "- grad 정의 과정에서 가중치가 hypothesis에 이미 계산되어 들어가면서 tape.gradient 가중치 지정이 의미 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11186be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grad(hypothesis, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(hypothesis,labels)\n",
    "    return tape.gradient(loss_value, [W,b])\n",
    "\n",
    "grad(hypothesis, labels)             # grad 계산값 없음."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
